{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.3.CNN.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "https://github.com/tomasriv/TallerDL/blob/master/DIA%201/1.2.Regresion_Logistica.ipynb",
          "timestamp": 1533071266921
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "COc0QERjJ4qx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparando Entorno\n",
        "Para iniciar nuestro notebook de Google Colab, es necesario correr los comandos necesarios para instalar pytorch y librerias auxiliares."
      ]
    },
    {
      "metadata": {
        "id": "uUZdTiohJ4qz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "4b9bbd5e-eb61-4fec-a657-4588426c16ad",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1533071345096,
          "user_tz": 360,
          "elapsed": 5004,
          "user": {
            "displayName": "Tomas Rivera",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112922286413704385048"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\r\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\r\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.2.0)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WIKXMY-qJ4q4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Si se requiere verificar que el notebook cuente con GPU asignada, se puede correr el siguiente comando:"
      ]
    },
    {
      "metadata": {
        "id": "E2LDlwp1J4q6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2972ccb9-da42-40e0-d984-81021e93f2e2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1533071347372,
          "user_tz": 360,
          "elapsed": 2198,
          "user": {
            "displayName": "Tomas Rivera",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112922286413704385048"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 31 21:09:06 2018       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   36C    P0    70W / 149W |    580MiB / 11439MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9zvzAg7eJ4q-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regresión logística (Logistic regresion)\n",
        "Importar las librerias en python"
      ]
    },
    {
      "metadata": {
        "id": "TIfAdA75J4q-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "import matplotlib\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I3ewMwnMJ4rB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PASO 1\n",
        "Cargar el dataset MNIST"
      ]
    },
    {
      "metadata": {
        "id": "fNz0h3yCJ4rC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h5f8GlEOJ4rF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PASO 2\n",
        "Hacer que nuestros dataset sean optimizados para un DataLoader (empaquetados)"
      ]
    },
    {
      "metadata": {
        "id": "dIw4QB6pJ4rG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZxRr6teJ4rO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PASO 3\n",
        "Crear la clase del modelo"
      ]
    },
    {
      "metadata": {
        "id": "9a3SkFfoJ4rP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        \n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        \n",
        "        # Max pool 1\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "     \n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        \n",
        "        # Max pool 2\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "        # Fully connected 1 (readout)\n",
        "        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Convolution 1\n",
        "        out = self.cnn1(x)\n",
        "        out = self.relu1(out)\n",
        "        \n",
        "        # Max pool 1\n",
        "        out = self.maxpool1(out)\n",
        "        \n",
        "        # Convolution 2 \n",
        "        out = self.cnn2(out)\n",
        "        out = self.relu2(out)\n",
        "        \n",
        "        # Max pool 2 \n",
        "        out = self.maxpool2(out)\n",
        "        \n",
        "        # Resize\n",
        "        # Original size: (100, 32, 7, 7)\n",
        "        # out.size(0): 100\n",
        "        # New out size: (100, 32*7*7)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        out = self.fc1(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ytYu7eO9J4rS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PASO 4\n",
        "Inicializar el modelo"
      ]
    },
    {
      "metadata": {
        "id": "WUdqocM7J4rU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = CNNModel()\n",
        "\n",
        "#######################\n",
        "#    SOLO PARA GPU    #\n",
        "#######################\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKFt-gvLJ4rY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PASO 5\n",
        "Inicializar el tipo de función de \"Loss\" y Optimizador"
      ]
    },
    {
      "metadata": {
        "id": "j6gf4rYNJ4rZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## LOSS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "## Optimizador\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbOndipbJ4re",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PASO 6\n",
        "Entrenar el modelo..."
      ]
    },
    {
      "metadata": {
        "id": "el40c7zJJ4rf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d2cf5db5-ab1d-42d7-edd3-1e1678050710"
      },
      "cell_type": "code",
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        #######################\n",
        "        #  USE GPU FOR MODEL  #\n",
        "        #######################\n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "        else:\n",
        "            images = Variable(images)\n",
        "            labels = Variable(labels)\n",
        "        \n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        iter += 1\n",
        "        \n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                if torch.cuda.is_available():\n",
        "                    images = Variable(images.cuda())\n",
        "                else:\n",
        "                    images = Variable(images)\n",
        "                \n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "                \n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "                \n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "            \n",
        "            accuracy = 100 * correct / total\n",
        "            \n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 0.3610345125198364. Accuracy: 89\n",
            "Iteration: 1000. Loss: 0.43508464097976685. Accuracy: 92\n",
            "Iteration: 1500. Loss: 0.1799713522195816. Accuracy: 94\n",
            "Iteration: 2000. Loss: 0.13399404287338257. Accuracy: 95\n",
            "Iteration: 2500. Loss: 0.19012333452701569. Accuracy: 95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4p3oio0wKJmF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}